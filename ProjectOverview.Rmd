---
title: "Project Overview - Can Yelp Reviews Save the Restaurant Industry?"
author: "Xinman Liu, Melissa Putur, Jiao Sun, Adil Bin Wahab, Rui Xu"
date: "2/14/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(jsonlite)
library(tidytext)
library(stringr)
library(ggplot2)
library(dplyr)
library(ggthemes)
library(readr)
library(tidyr)
library(lubridate)
```

```{r message=FALSE, warning=FALSE}
#Loading the datasets
#restaurants <- read_csv("/Users/Adil/Documents/RStudio/cananda_restaurant.csv") #adil file path
#resNotCleaned <- read_csv("Data/Canada minus Montreal Review Count.csv")
#restaurants <- read_csv("Data/canada_restaurants_ms.csv") #missy file path
restaurants <- read_csv("Data/canada_restaurants_ms_edits.csv")
#dim(restaurants)
#reviews <- read_csv("/Users/Adil/Documents/RStudio/capstoneData/canada_reviews.csv") #adil file path
reviews <- read_csv("Data/canada_reviews_ms.csv") #missy file path
#checkIns <- read_csv("/Users/Adil/Documents/RStudio/capstoneData/canada_checkin.csv")
checkin <- read_csv("Data/canada_checkins_ms.csv")
```


### Business Problem   
Finding restaurants through directory services apps and review forum apps have become a crucial part of business discovery. It has changed the way restaurants of different tiers attain brand loyalty and market themselves.   

Yelp’s terabytes of historical data on restaurants’ reviews, check-ins, and special attributes have led to the ability to uncover valuable trends to aid businesses in understanding their impact on customers and what make customers tick.   

How can a restaurant leverage information on Yelp to increase their chances of attaining their business goals and preventing permanent closure? What aspects make customers choose a restaurant over its competitors? 


### Ways to Solve Our Problem
**1. descriptive + diagnostic analytics**
Study the most essential aspects of a restaurant based on cuisine and price level to understand what most customers value (e.g. Do customers at low-price restaurants value the same “things” as mid-price and high-price restaurants).
**2. predictive analytics**
Predict whether a restaurant will close in the near future based on specific variables.
**3. prescriptive Analytics**
Create a recommendation system that predicts users’ preferences based on their reviews. prescriptive Analytics


### Data Source   
We got our data from [Kaggle](https://www.kaggle.com/yelp-dataset/yelp-dataset), and there are 4 datasets in total, namely, business, check-in, reviews, and users. 
**Business dataset** includes business types, attributes, location, review count, star ratings, and open hours.
**User dataset** about reviews on each business: text, rating, review count, and reactions (useful, cool, funny).
**Check-ins datasets** includes the exact timestamp a user checked into a business.
**Review dataset** includes the review text of each business with user ids, usefulness count, and reactions (useful, cool, funny).


### Data Cleaning
**Business Dataset:** For the project we are only interested in exploring reviews, star ratings, and interactions with restaurants. The business dataset contains information for all business reviewed by yelp. To narrow down this dataset we manually reviewed the top 1,000 phrases that businesses were tagged with to identify phrases that would be a good fit for restaurant. We filtered the complete list to only include businesses that were tagged with the phrases “food” and/or “restaurant”. Using these phrases we were able to identify ~75,000 restaurants. 
**Review Dataset:** The review dataset contains reviews for all businesses on Yelp. We reduced the review dataset to only include reviews for restaurants (as identified by the above processing steps). After this reduction the dataset contained over 4 million reviews.
**Check-In Dataset:** The check-in dataset was structured so that each business was represented as a row with a comma separated list of check-ins by date. To make the data easier to work with we rearranged it so that each check-in was represented as a row rather than a list.
**Final Data Cleaning Criteria:** To balance having a robust datset that minimizes long compute time while preserving data quality, the dataset was filtered to only include Canadian cities (Toronto, Mississauga and Calgary). Montréal was excluded as a majority of the reviews are in French. Furthermore to ensure rich, non-sparse data for for the remainder of restaurants in the dataset, we futher reduced the restaurant list to include only the restaurants with the top 50% of reviews. With this criteria only restaurants with 14+ reviews remained. 
**Post-cleaned Dataset Information**: 
Table 1: Number of reviews of each resturant (`nrow(reviews)` rows) - 200 KB (CSV)
Table 2: Restaurant general info and attributes (`nrow(restaurants)` rows) - reduced to 4 MB (CSV) from 34 MB (JSON)
Table 3: Restuarant check-ins (`nrow(checkin)` rows) - reduced to 38.5 MB (CSV) from 390 MB (JSON)
Table 4: Restaurant reviews (371,610 rows) - reduced to 320 MB (CSV) from 4.98 GB (JSON)

###Exploratory Data Analysis

##Restaurants Exploratory Data Analysis 

There are 1,422 restaurants in Calgary, 808 restaurants in Mississauga, Toronto has the most restaurants with 5,547.
```{r}
# restaurants are in each city
#restaurants %>% group_by(city) %>% count(city)
restaurants %>% 
  ggplot(aes(x=city))+
  geom_bar(fill=c("#F15C4F", "#FCD6D3","#F8ADA8"))+
  theme_classic()+
  labs(title = "Restaurant Distribution by City",
       y="# of Restaurants") +
  theme(axis.text = element_text(size = 13)) +
  theme(axis.title = element_text(size = 13)) 
```

Approximately 6,000 restaurants in the dataset are open and approximately 2,000 restaurants have closed. 
```{r}
open <- restaurants %>% group_by(is_open) %>% count(is_open)
open[open$is_open==0,1]="no"
open[open$is_open==1,1]="yes"
open %>% 
  ggplot(aes(is_open,n))+
  geom_col(fill=c("#F15C4F", "#F8ADA8"))+
  labs(title = "Current Restuarant Status",
       x="Still in Business?",
       y="# of Restaurants")+
  theme_classic() +
   theme(axis.text = element_text(size = 13)) +
  theme(axis.title = element_text(size = 13)) 
```

The majority of the restaurants in the dataset are in the second lowest, or "2-Dollar-Sign" price range. 
```{r message=FALSE, warning=FALSE}
restaurants %>% 
  ggplot(aes(attributes_RestaurantsPriceRange2))+
  geom_histogram(binwidth=1,fill="#F15C4F",color="#4D4D4D")+
  labs(title = "Distribution of Price Range",
       x="Price Range")+
  theme_classic()
```

##Reviews Exploratory Data Analysis
The dataset contains `nrow(reviews)` for `nrow(restaurants)` restaurants. On average, each restaurant has 48 reviews. 
```{r message=FALSE, warning=FALSE}
print(paste0("number of reviews: ", nrow(reviews)))
print(paste0("average # of reviews: ", round(nrow(reviews)/nrow(restaurants))))
#summary(reviews)
```

The distribution of the review length is right-skewed with a mode of around 30 to 60 words, which represents the word count of over 20% of all reviews. More than 50% of all the reviews are between 30 to 120 words. The average review length is around 130 words while the median is around 100 words. 
```{r}
review_length <- sapply(strsplit(reviews$text, " "), length)
review_length <- as.data.frame(review_length)

# Dist freq 
ggplot(data=review_length, aes(x=review_length)) +
geom_histogram(aes(y = stat(count) / sum(count)),
               bins = 25, fill="#D32323") +
  scale_y_continuous(labels = scales::percent) +
  labs(title="Distribution of Review Length",
       x="Review Length",y="Relative Frequency") +
  theme_minimal() + scale_x_continuous(breaks=seq(0,1000,25)) +
  theme(axis.text.x=element_text(angle=90, hjust=1))

```

```{r}
print(paste0("mean ", (round(mean(review_length$review_length)))))
print(paste0("median ", (median(review_length$review_length))))
```

Reviewers giving 1 and 2 star reviews wrote longer reviews that reviewers giving 3, 4, and 5 star reviews. The average length of 2 star reviews, the shortest average reviews were 150 words, while the average length of 5 star reviews, the longest average reviews is 113 words. 

```{r}
reviews$review_length <- review_length$review_length

reviews %>%
  group_by(stars) %>% 
  summarise(avgLength = round(mean(review_length))) %>% 
  arrange(desc(avgLength)) %>% 
  ggplot() +
  geom_col(aes(x = stars, y = avgLength), fill = "#F8ADA8") +
  labs(title="Star Rating by Review Length",
       x="Star Rating",y="Avg Review Length (words)") +
  theme_minimal() +
  theme(axis.text = element_text(size = 13)) +
  theme(axis.title = element_text(size = 13)) 
```

```{r}
#Missy still working on this chart - will show star ratings by number of reviews written
#want to show if people with less reviews 

#number of reviews by average star rating
reviews$avg_stars_buckets <- cut(x = reviews$average_stars, breaks = c(0,1,2,3,4,5))
reviews$review_count <- cut()
reviews %>% 
  select(review_count, average_stars_buckets) %>% 
  distinct() +
  
  
  
#distance_buckets <- cut(x = delayed_flights_only$DISTANCE, breaks = c(0,500,1000,1500,2000,2500,3000))
#levels(distance_buckets) <- c("<500","501 - 1000", "1001 - 1500", "1501 - 2000", "2001 - 2500","2501 - 3000",">3000")
#delayed_flights_only$distance_buckets <- distance_buckets
```



## Check-Ins Exploratory Data Analysis:

```{r}
#rachel making new chart

#manually make a bar chart - last bucket will be over 1000 checkin 
checkin %>% 
  group_by(business_id) %>% 
  count(.) %>% 
  ggplot() +
  geom_histogram(aes(x = n), fill="#D32323", binwidth = 10) +
  labs(title="Distribution of Check-In Count", x = "Check-Ins")+
  theme_classic()


postcount[postcount$review_count >= 1000, "review_count"] = 1000
postcount %>%
  ggplot() +
  geom_histogram(aes(x = review_count), bins = 25, color = 'white') +
  labs(title = 'Review Distribution',
       x = 'review') +
  theme_minimal()


checkins$checkinbucket <- checkins$updatedcheckins

#checkins[checkins$checkinbucket >= 1000, "checkinbucket2"] = 1000

checkins$checkinbucket <- ifelse(checkins$checkinbucket > 999, 1000, checkins$checkinbucket)

checkin %>% 
  group_by(business_id) %>% 
  count(.) %>% 
  ggplot() +
  geom_histogram(aes(x = n), fill="#D32323", binwidth = 10) +
  labs(title="Distribution of Check-In Count", x = "Check-Ins")+
  theme_minimal()


```

```{r}
restaurants %>% 
  ggplot() +
  geom_bar(aes(x = stars) , fill = "#F15C4F") + 
  theme_minimal() +
  labs(title="Distribution of Check-In Count", x = "Star Rating", y = "# of Restaurants") +
 theme(axis.text = element_text(size = 13)) +
  theme(axis.title = element_text(size = 13)) 
```


```{r message=FALSE, warning=FALSE}
### Checkins by Star Ratings
restaurants$business_id=as.character(restaurants$business_id)
new_table=left_join(x=checkin,y=restaurants)
checkin_count=new_table %>% group_by(stars) %>% count(.)
#glimpse(new_table)
ggplot(new_table, aes(x=stars)) +
  geom_histogram(stat="count",fill="#D32323") +
  labs(title="Checkins by Star Ratings")+
  theme_classic()
##4 stars have the largest numbers of checkins, followed by 3.5 and 3. While 5 and 1 stars
##have the smallest number of checkins maybe because it is too expensive.
```

```{r}
### Distribution of star ratings
ggplot(restaurants)+
  geom_bar(aes(x=city,fill=factor(stars)),position="dodge")+
  labs(title="Distribution of star ratings in Different City") +
  scale_fill_manual(values = c("#D32323", "#F15C4F", "#F8ADA8", "#FCD6D3", "#E6E6E6", "#999999", "#CCCCCC","#666666","#4D4D4D","#333333")) +
  theme_minimal()
##Toronto has the largest number of hotels, and Toronto also has the largest number of 5, 4 
##and 3 stars resutaurants.
```

##Check-In EDA

Check-Ins steadily increased year over year until about 2015 when they capped out. 2018 was the first year to see a decrease in checkins. In general customers check in more frequently in summer months than winter months. 
```{r}
checkin %>% 
  group_by(updatedcheckins) %>% 
  add_count() %>% 
  ggplot() +
  geom_smooth(aes(x = month(updatedcheckins), y = n, color = as.factor(year(updatedcheckins))), size = 2) + 
  theme_minimal()+
  theme(axis.text.x=element_text(angle=90, hjust=1)) +
  labs(title = "Check-In by Day", x = "month", y="count", color = "year") +
  scale_x_continuous(breaks=seq(0,12,1)) +
  scale_colour_manual(values = c("#D32323","#F15C4F","#F8ADA8","#FCD6D3","#E6E6E6","#999999","#CCCCCC","#666666","#4D4D4D","#333333"))
```

